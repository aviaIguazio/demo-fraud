{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Validation Pipeline\n",
    "Now that you have created features, you can use them to train one or more models. In this section, you will generate feature vectors with multiple features from one or more feature sets and feed them into an automated ML training and testing pipeline to create high-quality models.\n",
    "\n",
    "The ML pipeline can be triggered and tracked manually during the interactive devel‐ opment, or it can be saved (into Git) and be executed automatically on a given schedule or as a reaction to different events (such as code modification, CI/CD, data changes, model drift, and so on). See MLRun project and CI/CD documentation for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'fraud-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-03 21:35:22,585 [info] Project loaded successfully: {'project_name': 'fraud-demo'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f573ab82f10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set project level parameters and save\n",
    "project.spec.params = {'label_column': 'label'}\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: project\n",
      "metadata:\n",
      "  name: fraud-demo-pengw\n",
      "  created: '2023-07-27T02:07:46.064000'\n",
      "spec:\n",
      "  params:\n",
      "    label_column: label\n",
      "  functions: []\n",
      "  workflows: []\n",
      "  artifacts: []\n",
      "  conda: ''\n",
      "  source: git@github.com:pengwei715/demo-fraud.git#refs/heads/feature/align_with_book\n",
      "  desired_state: online\n",
      "  owner: pengw\n",
      "  build:\n",
      "    commands: []\n",
      "    requirements: []\n",
      "  custom_packagers: []\n",
      "status:\n",
      "  state: online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading projects from GIT\n",
    "\n",
    "After you saved your project and its elements (functions, workflows, artifacts, etc.) you can commit all your changes to a \n",
    "GIT repository. This can be done using standard GIT tools or using MLRun `project` methods such as `pull`, `push`, \n",
    "`remote`, which calls the Git API for you.\n",
    "\n",
    "Projects can then be loaded from Git using MLRun `load_project` method, for example: \n",
    "\n",
    "    project = mlrun.load_project(\"./myproj\", \"git://github.com/mlrun/project-demo.git\", name=project_name)\n",
    "    \n",
    "or using MLRun CLI:\n",
    "\n",
    "    mlrun project -n myproj -u \"git://github.com/mlrun/project-demo.git\" ./myproj\n",
    "    \n",
    "Read [CI/CD integration](../../projects/ci-integration.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Evaluating a Feature Vector\n",
    "\n",
    "Models are trained with multiple features, which can arrive from different feature sets and be collected into training (feature) vectors. Feature stores know how to correctly combine the features into a vector by implementing smart JOINs and assessing the time dimension (time traveling).\n",
    "To define a feature vector, you need to specify a name, the list of features it contains, the target features (labels), and other optional parameters. Features are specified as `<FeatureSet>.<Feature> or <FeatureSet>.*`  (all the features in a feature set). The following part demonstrates how to create and use a feature vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Define the list of features to use\n",
    "features = ['events.*',\n",
    "            'transactions.amount_max_2h', \n",
    "            'transactions.amount_sum_2h', \n",
    "            'transactions.amount_count_2h',\n",
    "            'transactions.amount_avg_2h', \n",
    "            'transactions.amount_max_12h', \n",
    "            'transactions.amount_sum_12h',\n",
    "            'transactions.amount_count_12h', \n",
    "            'transactions.amount_avg_12h', \n",
    "            'transactions.amount_max_24h',\n",
    "            'transactions.amount_sum_24h', \n",
    "            'transactions.amount_count_24h', \n",
    "            'transactions.amount_avg_24h',\n",
    "            'transactions.es_transportation_sum_14d', \n",
    "            'transactions.es_health_sum_14d',\n",
    "            'transactions.es_otherservices_sum_14d', \n",
    "            'transactions.es_food_sum_14d',\n",
    "            'transactions.es_hotelservices_sum_14d', \n",
    "            'transactions.es_barsandrestaurants_sum_14d',\n",
    "            'transactions.es_tech_sum_14d', \n",
    "            'transactions.es_sportsandtoys_sum_14d',\n",
    "            'transactions.es_wellnessandbeauty_sum_14d', \n",
    "            'transactions.es_hyper_sum_14d',\n",
    "            'transactions.es_fashion_sum_14d', \n",
    "            'transactions.es_home_sum_14d', \n",
    "            'transactions.es_travel_sum_14d', \n",
    "            'transactions.es_leisure_sum_14d',\n",
    "            'transactions.gender_F',\n",
    "            'transactions.gender_M',\n",
    "            'transactions.step', \n",
    "            'transactions.amount', \n",
    "            'transactions.timestamp_hour',\n",
    "            'transactions.timestamp_day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature vector name for future reference\n",
    "fv_name = 'transactions-fraud'\n",
    "\n",
    "# Define the feature vector using the feature store (fstore)\n",
    "transactions_fv = fstore.FeatureVector(fv_name, \n",
    "                          features, \n",
    "                          label_feature=\"labels.label\",\n",
    "                          description='Predicting a fraudulent transaction')\n",
    "\n",
    "# Save the feature vector in the feature store\n",
    "transactions_fv.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the feature vector data\n",
    "\n",
    "Obtain the values of the features in the feature vector, to ensure the data appears as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-03 21:39:07,027 [info] wrote target: {'name': 'parquet', 'kind': 'parquet', 'path': 'v3io:///projects/fraud-demo-pengw/FeatureStore/transactions-fraud/parquet/vectors/transactions-fraud-latest.parquet', 'status': 'ready', 'updated': '2023-08-03T21:39:07.027688+00:00', 'size': 150966, 'partitioned': True}\n"
     ]
    }
   ],
   "source": [
    "# Import the Parquet Target so you can directly save your dataset as a file\n",
    "from mlrun.datastore.targets import ParquetTarget\n",
    "\n",
    "# Get offline feature vector as dataframe and save the dataset to parquet\n",
    "train_dataset = fstore.get_offline_features(fv_name, target=ParquetTarget())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_password_change</th>\n",
       "      <th>event_details_change</th>\n",
       "      <th>event_login</th>\n",
       "      <th>amount_max_2h</th>\n",
       "      <th>amount_sum_2h</th>\n",
       "      <th>amount_count_2h</th>\n",
       "      <th>amount_avg_2h</th>\n",
       "      <th>amount_max_12h</th>\n",
       "      <th>amount_sum_12h</th>\n",
       "      <th>amount_count_12h</th>\n",
       "      <th>...</th>\n",
       "      <th>es_home_sum_14d</th>\n",
       "      <th>es_travel_sum_14d</th>\n",
       "      <th>es_leisure_sum_14d</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp_hour</th>\n",
       "      <th>timestamp_day_of_week</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74.89</td>\n",
       "      <td>74.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.890000</td>\n",
       "      <td>74.89</td>\n",
       "      <td>74.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>74.89</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.92</td>\n",
       "      <td>67.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.985000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>67.94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.085000</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_password_change  event_details_change  event_login  amount_max_2h  \\\n",
       "0                      0                     0            1          74.89   \n",
       "1                      0                     0            1           1.83   \n",
       "2                      0                     0            1          18.72   \n",
       "3                      1                     0            0          25.92   \n",
       "4                      1                     0            0          24.75   \n",
       "\n",
       "   amount_sum_2h  amount_count_2h  amount_avg_2h  amount_max_12h  \\\n",
       "0          74.89              1.0      74.890000           74.89   \n",
       "1           1.83              1.0       1.830000            1.83   \n",
       "2          40.22              3.0      13.406667           18.72   \n",
       "3          67.94              4.0      16.985000           25.92   \n",
       "4          30.17              2.0      15.085000           24.75   \n",
       "\n",
       "   amount_sum_12h  amount_count_12h  ...  es_home_sum_14d  es_travel_sum_14d  \\\n",
       "0           74.89               1.0  ...              0.0                0.0   \n",
       "1            1.83               1.0  ...              0.0                0.0   \n",
       "2           40.22               3.0  ...              0.0                0.0   \n",
       "3           67.94               4.0  ...              0.0                0.0   \n",
       "4           30.17               2.0  ...              0.0                0.0   \n",
       "\n",
       "   es_leisure_sum_14d  gender_F  gender_M   step  amount  timestamp_hour  \\\n",
       "0                 0.0       0.0       1.0   55.0   74.89            21.0   \n",
       "1                 0.0       0.0       1.0   72.0    1.83            21.0   \n",
       "2                 0.0       0.0       1.0   66.0   18.72            21.0   \n",
       "3                 0.0       0.0       1.0   29.0    3.08            21.0   \n",
       "4                 0.0       0.0       1.0  141.0   24.75            21.0   \n",
       "\n",
       "   timestamp_day_of_week  label  \n",
       "0                    1.0    0.0  \n",
       "1                    1.0    0.0  \n",
       "2                    1.0    0.0  \n",
       "3                    1.0    0.0  \n",
       "4                    1.0    0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview your dataset\n",
    "train_dataset.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running an Automated Training and Validation Pipeline\n",
    "\n",
    "MLRun allows the building of distributed ML pipelines that can handle data process‐ ing, automated feature selection, training, optimization, testing, deployments, and so on. Pipelines are composed of steps that run or deploy custom or library (from the MLRun hub) serverless functions. Pipelines can be run locally (for debugging or small-scale tasks), on a scalable Kubernetes cluster (using Kubeflow), or in a CI/CD system.\n",
    "\n",
    "The example consists of the following pipeline steps (all using pre-defined MLRun hub functions):\n",
    "\n",
    "1. Materialize a feature vector (using hub://get_offline_features). \n",
    "2. Select the most optimal features (using ``).\n",
    "3. Train the model with multiple algorithms (using hub://auto_trainer).\n",
    "4. Evaluate the model (using hub://auto_trainer).\n",
    "5. Deploy the model and its application to the test cluster (using hub:// v2_model_server). The next section will explain the model and application pipe‐ line in detail.\n",
    "\n",
    "Each step can accept the previous steps’ results or data, and generate results, multiple visual artifacts/charts, versioned data objects, and registered models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(name=\"Fraud Detection Pipeline\",description=\"Detecting fraud from a transactions dataset\",)\n",
    "def pipeline( vector_name=\"transactions-fraud\", features=[], label_column=\"is_error\",):\n",
    "    project = mlrun.get_current_project() # Get FeatureVector\n",
    "    get_vector = mlrun.run_function(\n",
    "        \"hub://get_offline_features\",\n",
    "        name=\"get_vector\",\n",
    "        params={'feature_vector': vector_name,\n",
    "        'features': features,\n",
    "        'label_feature': label_column, \"entity_timestamp_column\": \"timestamp\", 'target': {'name': 'parquet', 'kind': 'parquet'}, \"update_stats\": True},\n",
    "        outputs=[\"feature_vector\"],\n",
    "    )\n",
    "    # Feature selection\n",
    "    feature_selection = mlrun.run_function(\n",
    "        \"hub://feature_selection\",\n",
    "        name=\"feature-selection\",\n",
    "        params={\n",
    "        \"output_vector_name\": \"short\",\n",
    "        \"label_column\": project.get_param(\"label_column\", \"label\"), \"k\": 18,\n",
    "        \"min_votes\": 2,\n",
    "        \"ignore_type_errors\": True,\n",
    "        }, \n",
    "        inputs={\"df_artifact\": get_vector.outputs['feature_vector']},\n",
    "        outputs=[\n",
    "        \"feature_scores\",\n",
    "        \"selected_features_count\",\n",
    "        \"top_features_vector\",\n",
    "        \"selected_features\",\n",
    "        ], \n",
    "    )\n",
    "    # train with hyper-paremeters\n",
    "    train = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"train\",\n",
    "        handler=\"train\",\n",
    "        params={\n",
    "            \"sample\": -1,\n",
    "            \"label_column\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"test_size\": 0.10,\n",
    "        },\n",
    "        hyperparams={\n",
    "            \"model_name\": [\n",
    "            \"transaction_fraud_rf\",\n",
    "            \"transaction_fraud_xgboost\",\n",
    "            \"transaction_fraud_adaboost\",\n",
    "        ],\n",
    "        \"model_class\": [\n",
    "            \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"sklearn.linear_model.LogisticRegression\",\n",
    "            \"sklearn.ensemble.AdaBoostClassifier\",\n",
    "        ], \n",
    "        },\n",
    "        hyper_param_options=HyperParamOptions(strategy=\"list\",\n",
    "                                          selector=\"max.accuracy\"),\n",
    "        inputs={\"dataset\": feature_selection.outputs[\"top_features_vector\"]},\n",
    "        outputs=[\"model\", \"test_set\"],\n",
    "    )\n",
    "    # test and visualize your model\n",
    "    test = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"evaluate\",\n",
    "        handler=\"evaluate\",\n",
    "        params={\n",
    "            \"label_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"model\": train.outputs[\"model\"],\n",
    "            \"drop_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "        },\n",
    "        inputs={\"dataset\": train.outputs[\"test_set\"]},\n",
    "    )\n",
    "    # Create a serverless function from the hub, add a feature enrichment router\n",
    "    # This will enrich and impute the request with data from the feature vector\n",
    "    serving_function = mlrun.import_function(\"hub://v2_model_server\",\n",
    "                                             new_name=\"serving\")\n",
    "    serving_function.set_topology(\n",
    "        \"router\",\n",
    "        mlrun.serving.routers.EnrichmentModelRouter( feature_vector_uri=\"short\", impute_policy={\"*\": \"$mean\"}), exist_ok=True\n",
    "    )\n",
    "    # Enable model monitoring\n",
    "    serving_function.set_tracking()\n",
    "    serving_function.save()\n",
    "    # deploy the model server, pass a list of trained models to serve\n",
    "    deploy = mlrun.deploy_function(\n",
    "        serving_function,\n",
    "        models=[{\"key\": \"fraud\", \"model_path\": train.outputs[\"model\"]}],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow/pipeline can be executed using the MLRun SDK (project.run() method) or using CLI commands (mlrun project), and can run directly from the source repo (GIT). See details in MLRun Projects and Automation documentation.\n",
    "\n",
    "You can set arguments and destinations for the different artifacts when you run the workflow. The pipeline progress and results are shown in the notebook. Alternatively, you can check the progress, logs, artifacts, and more, in the MLRun UI or the CI/CD system. The next part demonstrates how to run the pipeline with custom arguments using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'src/new_train_workflow.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running a pipeline\n",
    "\n",
    "First run the following code to save your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f573ab82f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `run` MLRun project method to execute your workflow pipeline with Kubeflow Pipelines.\n",
    "\n",
    "You can pass **`arguments`** or set the **`artifact_path`** to specify a unique path for storing the workflow artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-03 22:01:10,097 [warning] WARNING!, you seem to have uncommitted git changes, use .push()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "There are no functions in the project. Make sure you've set your functions with project.set_function().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvector_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransactions-fraud\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels.label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/project.py:2215\u001b[0m, in \u001b[0;36mMlrunProject.run\u001b[0;34m(self, name, workflow_path, arguments, artifact_path, workflow_handler, namespace, sync, watch, dirty, ttl, engine, local, schedule, timeout, overwrite, source, cleanup_ttl)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_functions(always\u001b[38;5;241m=\u001b[39msync)\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39m_function_objects:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are no functions in the project.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Make sure you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve set your functions with project.set_function().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2218\u001b[0m     )\n\u001b[1;32m   2220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m workflow_path \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m workflow_handler:\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mworkflows:\n",
      "\u001b[0;31mValueError\u001b[0m: There are no functions in the project. Make sure you've set your functions with project.set_function()."
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={'vector_name':\"transactions-fraud\",\n",
    "                'label_column':\"labels.label\",}, \n",
    "    dirty=True, watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UI - WorkFlow](images/pipline-ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the model endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your model is deployed using the pipeline, you can invoke it as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-06-25 07:41:57,968 [info] invoking function: {'method': 'POST', 'path': 'http://nuclio-fraud-demo-admin-serving.default-tenant.svc.cluster.local:8080/v2/models/fraud/infer'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'e9463e2e-5cff-4015-82e2-70594013b3f2',\n",
       " 'model_name': 'fraud',\n",
       " 'outputs': [0]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define your serving function\n",
    "serving_fn = project.get_function('serving')\n",
    "\n",
    "# Choose an id for your test\n",
    "sample_id = 'C1000148617'\n",
    "model_inference_path = '/v2/models/fraud/infer'\n",
    "\n",
    "# Send our sample ID for predcition\n",
    "serving_fn.invoke(path=model_inference_path,\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You've completed Part 2 of the model training with the feature store.\n",
    "Proceed to part 5 to learn how to deploy and monitor the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proof-reading",
   "language": "python",
   "name": "conda-env-.conda-proof-reading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
