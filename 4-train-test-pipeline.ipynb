{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Validation Pipeline\n",
    "Now that you have created features, you can use them to train one or more models. In this section, you will generate feature vectors with multiple features from one or more feature sets and feed them into an automated ML training and testing pipeline to create high-quality models.\n",
    "\n",
    "The ML pipeline can be triggered and tracked manually during the interactive devel‐ opment, or it can be saved (into Git) and be executed automatically on a given schedule or as a reaction to different events (such as code modification, CI/CD, data changes, model drift, and so on). See MLRun project and CI/CD documentation for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'fraud-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 16:00:41,005 [info] Project loaded successfully: {'project_name': 'fraud-demo'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f57391d4d00>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set project level parameters and save\n",
    "project.spec.params = {'label_column': 'label'}\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: project\n",
      "metadata:\n",
      "  name: fraud-demo-pengw\n",
      "  created: '2023-07-27T02:07:46.064000'\n",
      "spec:\n",
      "  params:\n",
      "    label_column: label\n",
      "  functions: []\n",
      "  workflows:\n",
      "  - path: src/new_train_workflow.py\n",
      "    name: main\n",
      "  artifacts: []\n",
      "  conda: ''\n",
      "  source: git@github.com:pengwei715/demo-fraud.git#refs/heads/feature/align_with_book\n",
      "  desired_state: online\n",
      "  owner: pengw\n",
      "  build:\n",
      "    commands: []\n",
      "    requirements: []\n",
      "  custom_packagers: []\n",
      "status:\n",
      "  state: online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading projects from GIT\n",
    "\n",
    "After you saved your project and its elements (functions, workflows, artifacts, etc.) you can commit all your changes to a \n",
    "GIT repository. This can be done using standard GIT tools or using MLRun `project` methods such as `pull`, `push`, \n",
    "`remote`, which calls the Git API for you.\n",
    "\n",
    "Projects can then be loaded from Git using MLRun `load_project` method, for example: \n",
    "\n",
    "    project = mlrun.load_project(\"./myproj\", \"git://github.com/mlrun/project-demo.git\", name=project_name)\n",
    "    \n",
    "or using MLRun CLI:\n",
    "\n",
    "    mlrun project -n myproj -u \"git://github.com/mlrun/project-demo.git\" ./myproj\n",
    "    \n",
    "Read [CI/CD integration](../../projects/ci-integration.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Evaluating a Feature Vector\n",
    "\n",
    "Models are trained with multiple features, which can arrive from different feature sets and be collected into training (feature) vectors. Feature stores know how to correctly combine the features into a vector by implementing smart JOINs and assessing the time dimension (time traveling).\n",
    "To define a feature vector, you need to specify a name, the list of features it contains, the target features (labels), and other optional parameters. Features are specified as `<FeatureSet>.<Feature> or <FeatureSet>.*`  (all the features in a feature set). The following part demonstrates how to create and use a feature vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Define the list of features to use\n",
    "features = ['events.*',\n",
    "            'transactions.amount_max_2h', \n",
    "            'transactions.amount_sum_2h', \n",
    "            'transactions.amount_count_2h',\n",
    "            'transactions.amount_avg_2h', \n",
    "            'transactions.amount_max_12h', \n",
    "            'transactions.amount_sum_12h',\n",
    "            'transactions.amount_count_12h', \n",
    "            'transactions.amount_avg_12h', \n",
    "            'transactions.amount_max_24h',\n",
    "            'transactions.amount_sum_24h', \n",
    "            'transactions.amount_count_24h', \n",
    "            'transactions.amount_avg_24h',\n",
    "            'transactions.es_transportation_sum_14d', \n",
    "            'transactions.es_health_sum_14d',\n",
    "            'transactions.es_otherservices_sum_14d', \n",
    "            'transactions.es_food_sum_14d',\n",
    "            'transactions.es_hotelservices_sum_14d', \n",
    "            'transactions.es_barsandrestaurants_sum_14d',\n",
    "            'transactions.es_tech_sum_14d', \n",
    "            'transactions.es_sportsandtoys_sum_14d',\n",
    "            'transactions.es_wellnessandbeauty_sum_14d', \n",
    "            'transactions.es_hyper_sum_14d',\n",
    "            'transactions.es_fashion_sum_14d', \n",
    "            'transactions.es_home_sum_14d', \n",
    "            'transactions.es_travel_sum_14d', \n",
    "            'transactions.es_leisure_sum_14d',\n",
    "            'transactions.gender_F',\n",
    "            'transactions.gender_M',\n",
    "            'transactions.step', \n",
    "            'transactions.amount', \n",
    "            'transactions.timestamp_hour',\n",
    "            'transactions.timestamp_day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature vector name for future reference\n",
    "fv_name = 'transactions-fraud'\n",
    "\n",
    "# Define the feature vector using the feature store (fstore)\n",
    "transactions_fv = fstore.FeatureVector(fv_name, \n",
    "                          features, \n",
    "                          label_feature=\"labels.label\",\n",
    "                          description='Predicting a fraudulent transaction')\n",
    "\n",
    "# Save the feature vector in the feature store\n",
    "transactions_fv.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the feature vector data\n",
    "\n",
    "Obtain the values of the features in the feature vector, to ensure the data appears as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 16:00:57,626 [info] wrote target: {'name': 'parquet', 'kind': 'parquet', 'path': 'v3io:///projects/fraud-demo-pengw/FeatureStore/transactions-fraud/parquet/vectors/transactions-fraud-latest.parquet', 'status': 'ready', 'updated': '2023-08-04T16:00:57.625950+00:00', 'size': 151180, 'partitioned': True}\n"
     ]
    }
   ],
   "source": [
    "# Import the Parquet Target so you can directly save your dataset as a file\n",
    "from mlrun.datastore.targets import ParquetTarget\n",
    "\n",
    "# Get offline feature vector as dataframe and save the dataset to parquet\n",
    "train_dataset = fstore.get_offline_features(fv_name, target=ParquetTarget())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_password_change</th>\n",
       "      <th>event_details_change</th>\n",
       "      <th>event_login</th>\n",
       "      <th>amount_max_2h</th>\n",
       "      <th>amount_sum_2h</th>\n",
       "      <th>amount_count_2h</th>\n",
       "      <th>amount_avg_2h</th>\n",
       "      <th>amount_max_12h</th>\n",
       "      <th>amount_sum_12h</th>\n",
       "      <th>amount_count_12h</th>\n",
       "      <th>...</th>\n",
       "      <th>es_home_sum_14d</th>\n",
       "      <th>es_travel_sum_14d</th>\n",
       "      <th>es_leisure_sum_14d</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp_hour</th>\n",
       "      <th>timestamp_day_of_week</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.92</td>\n",
       "      <td>64.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.620000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>64.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.92</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.085000</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.18</td>\n",
       "      <td>65.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.585000</td>\n",
       "      <td>64.18</td>\n",
       "      <td>65.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>64.18</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_password_change  event_details_change  event_login  amount_max_2h  \\\n",
       "0                      0                     0            1           1.83   \n",
       "1                      0                     0            1          18.72   \n",
       "2                      1                     0            0          25.92   \n",
       "3                      1                     0            0          24.75   \n",
       "4                      1                     0            0          64.18   \n",
       "\n",
       "   amount_sum_2h  amount_count_2h  amount_avg_2h  amount_max_12h  \\\n",
       "0           1.83              1.0       1.830000            1.83   \n",
       "1          40.22              3.0      13.406667           18.72   \n",
       "2          64.86              3.0      21.620000           25.92   \n",
       "3          30.17              2.0      15.085000           24.75   \n",
       "4          65.17              2.0      32.585000           64.18   \n",
       "\n",
       "   amount_sum_12h  amount_count_12h  ...  es_home_sum_14d  es_travel_sum_14d  \\\n",
       "0            1.83               1.0  ...              0.0                0.0   \n",
       "1           40.22               3.0  ...              0.0                0.0   \n",
       "2           64.86               3.0  ...              0.0                0.0   \n",
       "3           30.17               2.0  ...              0.0                0.0   \n",
       "4           65.17               2.0  ...              0.0                0.0   \n",
       "\n",
       "   es_leisure_sum_14d  gender_F  gender_M   step  amount  timestamp_hour  \\\n",
       "0                 0.0       0.0       1.0   72.0    1.83            22.0   \n",
       "1                 0.0       0.0       1.0   66.0   18.72            22.0   \n",
       "2                 0.0       0.0       1.0   27.0   25.92            22.0   \n",
       "3                 0.0       0.0       1.0  141.0   24.75            22.0   \n",
       "4                 0.0       1.0       0.0  124.0   64.18            22.0   \n",
       "\n",
       "   timestamp_day_of_week  label  \n",
       "0                    1.0    0.0  \n",
       "1                    1.0    0.0  \n",
       "2                    1.0    0.0  \n",
       "3                    1.0    0.0  \n",
       "4                    1.0    0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview your dataset\n",
    "train_dataset.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running an Automated Training and Validation Pipeline\n",
    "\n",
    "MLRun allows the building of distributed ML pipelines that can handle data process‐ ing, automated feature selection, training, optimization, testing, deployments, and so on. Pipelines are composed of steps that run or deploy custom or library (from the MLRun hub) serverless functions. Pipelines can be run locally (for debugging or small-scale tasks), on a scalable Kubernetes cluster (using Kubeflow), or in a CI/CD system.\n",
    "\n",
    "The example consists of the following pipeline steps (all using pre-defined MLRun hub functions):\n",
    "\n",
    "1. Materialize a feature vector (using `hub://get_offline_features`). \n",
    "2. Select the most optimal features (using `hub://feature_selection`).\n",
    "3. Train the model with multiple algorithms (using `hub://auto_trainer`).\n",
    "4. Evaluate the model (using `hub://auto_trainer`).\n",
    "5. Deploy the model and its application to the test cluster (using `hub://v2_model_server`). The next section will explain the model and application pipeline in detail.\n",
    "\n",
    "Each step can accept the previous steps’ results or data, and generate results, multiple visual artifacts/charts, versioned data objects, and registered models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "from kfp import dsl\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(name=\"Fraud Detection Pipeline\",description=\"Detecting fraud from a transactions dataset\",)\n",
    "def pipeline( vector_name=\"transactions-fraud\", features=[], label_column=\"is_error\",):\n",
    "    project = mlrun.get_current_project() # Get FeatureVector\n",
    "    get_vector = mlrun.run_function(\n",
    "        \"hub://get_offline_features\",\n",
    "        name=\"get_vector\",\n",
    "        params={'feature_vector': vector_name,\n",
    "        'features': features,\n",
    "        'label_feature': label_column, \"entity_timestamp_column\": \"timestamp\", 'target': {'name': 'parquet', 'kind': 'parquet'}, \"update_stats\": True},\n",
    "        outputs=[\"feature_vector\"],\n",
    "    )\n",
    "    # Feature selection\n",
    "    feature_selection = mlrun.run_function(\n",
    "        \"hub://feature_selection\",\n",
    "        name=\"feature-selection\",\n",
    "        params={\n",
    "        \"output_vector_name\": \"short\",\n",
    "        \"label_column\": project.get_param(\"label_column\", \"label\"), \"k\": 18,\n",
    "        \"min_votes\": 2,\n",
    "        \"ignore_type_errors\": True,\n",
    "        }, \n",
    "        inputs={\"df_artifact\": get_vector.outputs['feature_vector']},\n",
    "        outputs=[\n",
    "        \"feature_scores\",\n",
    "        \"selected_features_count\",\n",
    "        \"top_features_vector\",\n",
    "        \"selected_features\",\n",
    "        ], \n",
    "    )\n",
    "    # train with hyper-paremeters\n",
    "    train = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"train\",\n",
    "        handler=\"train\",\n",
    "        params={\n",
    "            \"sample\": -1,\n",
    "            \"label_column\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"test_size\": 0.10,\n",
    "        },\n",
    "        hyperparams={\n",
    "            \"model_name\": [\n",
    "            \"transaction_fraud_rf\",\n",
    "            \"transaction_fraud_xgboost\",\n",
    "            \"transaction_fraud_adaboost\",\n",
    "        ],\n",
    "        \"model_class\": [\n",
    "            \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"sklearn.linear_model.LogisticRegression\",\n",
    "            \"sklearn.ensemble.AdaBoostClassifier\",\n",
    "        ], \n",
    "        },\n",
    "        hyper_param_options=HyperParamOptions(strategy=\"list\",\n",
    "                                          selector=\"max.accuracy\"),\n",
    "        inputs={\"dataset\": feature_selection.outputs[\"top_features_vector\"]},\n",
    "        outputs=[\"model\", \"test_set\"],\n",
    "    )\n",
    "    # test and visualize your model\n",
    "    test = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"evaluate\",\n",
    "        handler=\"evaluate\",\n",
    "        params={\n",
    "            \"label_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"model\": train.outputs[\"model\"],\n",
    "            \"drop_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "        },\n",
    "        inputs={\"dataset\": train.outputs[\"test_set\"]},\n",
    "    )\n",
    "    # Create a serverless function from the hub, add a feature enrichment router\n",
    "    # This will enrich and impute the request with data from the feature vector\n",
    "    serving_function = mlrun.import_function(\"hub://v2_model_server\",\n",
    "                                             new_name=\"serving\")\n",
    "    serving_function.set_topology(\n",
    "        \"router\",\n",
    "        mlrun.serving.routers.EnrichmentModelRouter( feature_vector_uri=\"short\", impute_policy={\"*\": \"$mean\"}), exist_ok=True\n",
    "    )\n",
    "    # Enable model monitoring\n",
    "    serving_function.set_tracking()\n",
    "    serving_function.save()\n",
    "    # deploy the model server, pass a list of trained models to serve\n",
    "    deploy = mlrun.deploy_function(\n",
    "        serving_function,\n",
    "        models=[{\"key\": \"fraud\", \"model_path\": train.outputs[\"model\"]}],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow/pipeline can be executed using the MLRun SDK (project.run() method) or using CLI commands (mlrun project), and can run directly from the source repo (GIT). See details in MLRun Projects and Automation documentation.\n",
    "\n",
    "You can set arguments and destinations for the different artifacts when you run the workflow. The pipeline progress and results are shown in the notebook. Alternatively, you can check the progress, logs, artifacts, and more, in the MLRun UI or the CI/CD system. The next part demonstrates how to run the pipeline with custom arguments using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'src/new_train_workflow.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running a pipeline\n",
    "\n",
    "First run the following code to save your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f57391d4d00>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `run` MLRun project method to execute your workflow pipeline with Kubeflow Pipelines.\n",
    "\n",
    "You can pass **`arguments`** or set the **`artifact_path`** to specify a unique path for storing the workflow artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 16:01:10,928 [warning] WARNING!, you seem to have uncommitted git changes, use .push()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "There are no functions in the project. Make sure you've set your functions with project.set_function().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvector_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransactions-fraud\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels.label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/project.py:2215\u001b[0m, in \u001b[0;36mMlrunProject.run\u001b[0;34m(self, name, workflow_path, arguments, artifact_path, workflow_handler, namespace, sync, watch, dirty, ttl, engine, local, schedule, timeout, overwrite, source, cleanup_ttl)\u001b[0m\n\u001b[1;32m   2213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync_functions(always\u001b[38;5;241m=\u001b[39msync)\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39m_function_objects:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are no functions in the project.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Make sure you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mve set your functions with project.set_function().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2218\u001b[0m     )\n\u001b[1;32m   2220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m workflow_path \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m workflow_handler:\n\u001b[1;32m   2221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mworkflows:\n",
      "\u001b[0;31mValueError\u001b[0m: There are no functions in the project. Make sure you've set your functions with project.set_function()."
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={'vector_name':\"transactions-fraud\",\n",
    "                'label_column':\"labels.label\"}, \n",
    "    dirty=True, watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UI - WorkFlow](images/pipline-ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the model endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your model is deployed using the pipeline, you can invoke it as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "MLRunNotFoundError",
     "evalue": "404 Client Error: Not Found for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/functions/serving?tag=&hash_key=: get function fraud-demo-pengw/serving details: MLRunNotFoundError('Function tag not found fraud-demo-pengw/serving')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/errors.py:94\u001b[0m, in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mHTTPError, aiohttp\u001b[38;5;241m.\u001b[39mClientResponseError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/functions/serving?tag=&hash_key=",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMLRunNotFoundError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define your serving function\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m serving_fn \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Choose an id for your test\u001b[39;00m\n\u001b[1;32m      5\u001b[0m sample_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC1000148617\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/project.py:1850\u001b[0m, in \u001b[0;36mMlrunProject.get_function\u001b[0;34m(self, key, sync, enrich, ignore_cache, copy_function, tag)\u001b[0m\n\u001b[1;32m   1847\u001b[0m     function, err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_function(key, sync, ignore_cache)\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enrich:\n\u001b[1;32m   1853\u001b[0m     function \u001b[38;5;241m=\u001b[39m enrich_function_object(\n\u001b[1;32m   1854\u001b[0m         \u001b[38;5;28mself\u001b[39m, function, copy_function\u001b[38;5;241m=\u001b[39mcopy_function\n\u001b[1;32m   1855\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/project.py:1876\u001b[0m, in \u001b[0;36mMlrunProject._get_function\u001b[0;34m(self, key, sync, ignore_cache)\u001b[0m\n\u001b[1;32m   1874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1875\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1876\u001b[0m         function \u001b[38;5;241m=\u001b[39m \u001b[43mget_db_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1877\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39m_function_objects[key] \u001b[38;5;241m=\u001b[39m function\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/pipelines.py:382\u001b[0m, in \u001b[0;36mget_db_function\u001b[0;34m(project, key)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_db_function\u001b[39m(project, key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m mlrun\u001b[38;5;241m.\u001b[39mruntimes\u001b[38;5;241m.\u001b[39mBaseRuntime:\n\u001b[1;32m    379\u001b[0m     project_instance, name, tag, hash_key \u001b[38;5;241m=\u001b[39m parse_versioned_object_uri(\n\u001b[1;32m    380\u001b[0m         key, project\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    381\u001b[0m     )\n\u001b[0;32m--> 382\u001b[0m     runtime \u001b[38;5;241m=\u001b[39m \u001b[43mmlrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_instance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mlrun\u001b[38;5;241m.\u001b[39mnew_function(runtime\u001b[38;5;241m=\u001b[39mruntime)\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/db/httpdb.py:850\u001b[0m, in \u001b[0;36mHTTPRunDB.get_function\u001b[0;34m(self, name, project, tag, hash_key)\u001b[0m\n\u001b[1;32m    848\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprojects/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/functions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    849\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 850\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/db/httpdb.py:237\u001b[0m, in \u001b[0;36mHTTPRunDB.api_call\u001b[0;34m(self, method, path, error, params, body, json, headers, timeout, version)\u001b[0m\n\u001b[1;32m    235\u001b[0m             error_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetails: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_details\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m             error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_details\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;28;01melse\u001b[39;00m error_details\n\u001b[0;32m--> 237\u001b[0m             \u001b[43mmlrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     mlrun\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mraise_for_status(response, error)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/errors.py:105\u001b[0m, in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m     99\u001b[0m status_code \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    100\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m STATUS_ERRORS[status_code](error_message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MLRunHTTPError(error_message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mMLRunNotFoundError\u001b[0m: 404 Client Error: Not Found for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/functions/serving?tag=&hash_key=: get function fraud-demo-pengw/serving details: MLRunNotFoundError('Function tag not found fraud-demo-pengw/serving')"
     ]
    }
   ],
   "source": [
    "# Define your serving function\n",
    "serving_fn = project.get_function('serving')\n",
    "\n",
    "# Choose an id for your test\n",
    "sample_id = 'C1000148617'\n",
    "model_inference_path = '/v2/models/fraud/infer'\n",
    "\n",
    "# Send our sample ID for predcition\n",
    "serving_fn.invoke(path=model_inference_path,\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You've completed Part 2 of the model training with the feature store.\n",
    "Proceed to part 5 to learn how to deploy and monitor the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proof-reading",
   "language": "python",
   "name": "conda-env-.conda-proof-reading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
