{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Validation Pipeline\n",
    "Now that you have created features, you can use them to train one or more models. In this section, you will generate feature vectors with multiple features from one or more feature sets and feed them into an automated ML training and testing pipeline to create high-quality models.\n",
    "\n",
    "The ML pipeline can be triggered and tracked manually during the interactive devel‐ opment, or it can be saved (into Git) and be executed automatically on a given schedule or as a reaction to different events (such as code modification, CI/CD, data changes, model drift, and so on). See MLRun project and CI/CD documentation for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'fraud-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 21:45:55,919 [info] Project loaded successfully: {'project_name': 'fraud-demo'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Names with underscore '_' are about to be deprecated, use dashes '-' instead. Replacing underscores with dashes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.serving.ServingRuntime at 0x7f5626b96e50>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"hub://get_offline_features\",\"get_vector\",)\n",
    "project.set_function(\"hub://feature_selection\",\"feature-selection\",)\n",
    "project.set_function(\"hub://auto_trainer\",\"train\")\n",
    "project.set_function(\"hub://auto_trainer\",\"evaluate\")\n",
    "project.set_function(\"hub://v2_model_server\", \"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f56430bd9a0>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set project level parameters and save\n",
    "project.spec.params = {'label_column': 'label'}\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: project\n",
      "metadata:\n",
      "  name: fraud-demo-pengw\n",
      "  created: '2023-08-04T18:02:33.655000'\n",
      "spec:\n",
      "  params:\n",
      "    label_column: label\n",
      "  functions:\n",
      "  - url: hub://feature_selection\n",
      "    name: feature-selection\n",
      "  - url: hub://auto_trainer\n",
      "    name: train\n",
      "  - url: hub://v2_model_server\n",
      "    name: serving\n",
      "  - url: hub://get_offline_features\n",
      "    name: get-vector\n",
      "  - url: hub://auto_trainer\n",
      "    name: evaluate\n",
      "  workflows:\n",
      "  - path: src/new_train_workflow.py\n",
      "    name: main\n",
      "  artifacts: []\n",
      "  conda: ''\n",
      "  source: git@github.com:pengwei715/demo-fraud.git#refs/heads/feature/align_with_book\n",
      "  origin_url: git@github.com:pengwei715/demo-fraud.git#refs/heads/feature/align_with_book\n",
      "  desired_state: online\n",
      "  owner: pengw\n",
      "  build:\n",
      "    commands: []\n",
      "    requirements: []\n",
      "  custom_packagers: []\n",
      "status:\n",
      "  state: online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading projects from GIT\n",
    "\n",
    "After you saved your project and its elements (functions, workflows, artifacts, etc.) you can commit all your changes to a \n",
    "GIT repository. This can be done using standard GIT tools or using MLRun `project` methods such as `pull`, `push`, \n",
    "`remote`, which calls the Git API for you.\n",
    "\n",
    "Projects can then be loaded from Git using MLRun `load_project` method, for example: \n",
    "\n",
    "    project = mlrun.load_project(\"./myproj\", \"git://github.com/mlrun/project-demo.git\", name=project_name)\n",
    "    \n",
    "or using MLRun CLI:\n",
    "\n",
    "    mlrun project -n myproj -u \"git://github.com/mlrun/project-demo.git\" ./myproj\n",
    "    \n",
    "Read [CI/CD integration](../../projects/ci-integration.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Evaluating a Feature Vector\n",
    "\n",
    "Models are trained with multiple features, which can arrive from different feature sets and be collected into training (feature) vectors. Feature stores know how to correctly combine the features into a vector by implementing smart JOINs and assessing the time dimension (time traveling).\n",
    "To define a feature vector, you need to specify a name, the list of features it contains, the target features (labels), and other optional parameters. Features are specified as `<FeatureSet>.<Feature> or <FeatureSet>.*`  (all the features in a feature set). The following part demonstrates how to create and use a feature vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Define the list of features to use\n",
    "features = ['events.*',\n",
    "            'transactions.amount_max_2h', \n",
    "            'transactions.amount_sum_2h', \n",
    "            'transactions.amount_count_2h',\n",
    "            'transactions.amount_avg_2h', \n",
    "            'transactions.amount_max_12h', \n",
    "            'transactions.amount_sum_12h',\n",
    "            'transactions.amount_count_12h', \n",
    "            'transactions.amount_avg_12h', \n",
    "            'transactions.amount_max_24h',\n",
    "            'transactions.amount_sum_24h', \n",
    "            'transactions.amount_count_24h', \n",
    "            'transactions.amount_avg_24h',\n",
    "            'transactions.es_transportation_sum_14d', \n",
    "            'transactions.es_health_sum_14d',\n",
    "            'transactions.es_otherservices_sum_14d', \n",
    "            'transactions.es_food_sum_14d',\n",
    "            'transactions.es_hotelservices_sum_14d', \n",
    "            'transactions.es_barsandrestaurants_sum_14d',\n",
    "            'transactions.es_tech_sum_14d', \n",
    "            'transactions.es_sportsandtoys_sum_14d',\n",
    "            'transactions.es_wellnessandbeauty_sum_14d', \n",
    "            'transactions.es_hyper_sum_14d',\n",
    "            'transactions.es_fashion_sum_14d', \n",
    "            'transactions.es_home_sum_14d', \n",
    "            'transactions.es_travel_sum_14d', \n",
    "            'transactions.es_leisure_sum_14d',\n",
    "            'transactions.gender_F',\n",
    "            'transactions.gender_M',\n",
    "            'transactions.step', \n",
    "            'transactions.amount', \n",
    "            'transactions.timestamp_hour',\n",
    "            'transactions.timestamp_day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature vector name for future reference\n",
    "fv_name = 'transactions-fraud'\n",
    "\n",
    "# Define the feature vector using the feature store (fstore)\n",
    "transactions_fv = fstore.FeatureVector(fv_name, \n",
    "                          features, \n",
    "                          label_feature=\"labels.label\",\n",
    "                          description='Predicting a fraudulent transaction')\n",
    "\n",
    "# Save the feature vector in the feature store\n",
    "transactions_fv.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'store://feature-vectors/fraud-demo-pengw/transactions-fraud'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_fv.uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the feature vector data\n",
    "\n",
    "Obtain the values of the features in the feature vector, to ensure the data appears as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 21:46:04,545 [info] wrote target: {'name': 'parquet', 'kind': 'parquet', 'path': 'v3io:///projects/fraud-demo-pengw/FeatureStore/transactions-fraud/parquet/vectors/transactions-fraud-latest.parquet', 'status': 'ready', 'updated': '2023-08-04T21:46:04.545602+00:00', 'size': 151216, 'partitioned': True}\n"
     ]
    }
   ],
   "source": [
    "# Import the Parquet Target so you can directly save your dataset as a file\n",
    "from mlrun.datastore.targets import ParquetTarget\n",
    "\n",
    "# Get offline feature vector as dataframe and save the dataset to parquet\n",
    "train_dataset = fstore.get_offline_features(fv_name, target=ParquetTarget())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_password_change</th>\n",
       "      <th>event_details_change</th>\n",
       "      <th>event_login</th>\n",
       "      <th>amount_max_2h</th>\n",
       "      <th>amount_sum_2h</th>\n",
       "      <th>amount_count_2h</th>\n",
       "      <th>amount_avg_2h</th>\n",
       "      <th>amount_max_12h</th>\n",
       "      <th>amount_sum_12h</th>\n",
       "      <th>amount_count_12h</th>\n",
       "      <th>...</th>\n",
       "      <th>es_home_sum_14d</th>\n",
       "      <th>es_travel_sum_14d</th>\n",
       "      <th>es_leisure_sum_14d</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp_hour</th>\n",
       "      <th>timestamp_day_of_week</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.92</td>\n",
       "      <td>64.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.620000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>64.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.92</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.085000</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.18</td>\n",
       "      <td>65.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.585000</td>\n",
       "      <td>64.18</td>\n",
       "      <td>65.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>64.18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_password_change  event_details_change  event_login  amount_max_2h  \\\n",
       "0                      0                     0            1           1.83   \n",
       "1                      0                     0            1          18.72   \n",
       "2                      1                     0            0          25.92   \n",
       "3                      1                     0            0          24.75   \n",
       "4                      1                     0            0          64.18   \n",
       "\n",
       "   amount_sum_2h  amount_count_2h  amount_avg_2h  amount_max_12h  \\\n",
       "0           1.83              1.0       1.830000            1.83   \n",
       "1          40.22              3.0      13.406667           18.72   \n",
       "2          64.86              3.0      21.620000           25.92   \n",
       "3          30.17              2.0      15.085000           24.75   \n",
       "4          65.17              2.0      32.585000           64.18   \n",
       "\n",
       "   amount_sum_12h  amount_count_12h  ...  es_home_sum_14d  es_travel_sum_14d  \\\n",
       "0            1.83               1.0  ...              0.0                0.0   \n",
       "1           40.22               3.0  ...              0.0                0.0   \n",
       "2           64.86               3.0  ...              0.0                0.0   \n",
       "3           30.17               2.0  ...              0.0                0.0   \n",
       "4           65.17               2.0  ...              0.0                0.0   \n",
       "\n",
       "   es_leisure_sum_14d  gender_F  gender_M   step  amount  timestamp_hour  \\\n",
       "0                 0.0       0.0       1.0   72.0    1.83            19.0   \n",
       "1                 0.0       0.0       1.0   66.0   18.72            19.0   \n",
       "2                 0.0       0.0       1.0   27.0   25.92            19.0   \n",
       "3                 0.0       0.0       1.0  141.0   24.75            19.0   \n",
       "4                 0.0       1.0       0.0  124.0   64.18            19.0   \n",
       "\n",
       "   timestamp_day_of_week  label  \n",
       "0                    2.0    0.0  \n",
       "1                    2.0    0.0  \n",
       "2                    2.0    0.0  \n",
       "3                    2.0    0.0  \n",
       "4                    2.0    0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview your dataset\n",
    "train_dataset.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running an Automated Training and Validation Pipeline\n",
    "\n",
    "MLRun allows the building of distributed ML pipelines that can handle data process‐ ing, automated feature selection, training, optimization, testing, deployments, and so on. Pipelines are composed of steps that run or deploy custom or library (from the MLRun hub) serverless functions. Pipelines can be run locally (for debugging or small-scale tasks), on a scalable Kubernetes cluster (using Kubeflow), or in a CI/CD system.\n",
    "\n",
    "The example consists of the following pipeline steps (all using pre-defined MLRun hub functions):\n",
    "\n",
    "1. Materialize a feature vector (using `hub://get_offline_features`). \n",
    "2. Select the most optimal features (using `hub://feature_selection`).\n",
    "3. Train the model with multiple algorithms (using `hub://auto_trainer`).\n",
    "4. Evaluate the model (using `hub://auto_trainer`).\n",
    "5. Deploy the model and its application to the test cluster (using `hub://v2_model_server`). The next section will explain the model and application pipeline in detail.\n",
    "\n",
    "Each step can accept the previous steps’ results or data, and generate results, multiple visual artifacts/charts, versioned data objects, and registered models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "from kfp import dsl\n",
    "\n",
    "from mlrun.model import HyperParamOptions\n",
    "\n",
    "\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(name=\"Fraud Detection Pipeline\",description=\"Detecting fraud from a transactions dataset\",)\n",
    "def pipeline( vector_name=\"transactions-fraud\", features=[], label_column=\"is_error\"):\n",
    "    project = mlrun.get_current_project() # Get FeatureVector\n",
    "    get_vector = mlrun.run_function(\n",
    "        \"hub://get_offline_features\",\n",
    "        name=\"get_vector\",\n",
    "        params={'feature_vector': vector_name,\n",
    "        'features': features,\n",
    "        'label_feature': label_column, \n",
    "        \"entity_timestamp_column\": \"timestamp\", \n",
    "        'target': {'name': 'parquet', 'kind': 'parquet'}, \n",
    "        \"update_stats\": True},\n",
    "        outputs=[\"feature_vector\"],\n",
    "    )\n",
    "    # Feature selection\n",
    "    feature_selection = mlrun.run_function(\n",
    "        \"hub://feature_selection\",\n",
    "        name=\"feature-selection\",\n",
    "        params={\n",
    "        \"output_vector_name\": \"short\",\n",
    "        \"label_column\": project.get_param(\"label_column\", \"label\"), \"k\": 18,\n",
    "        \"min_votes\": 2,\n",
    "        \"ignore_type_errors\": True,\n",
    "        }, \n",
    "        inputs={\"df_artifact\": get_vector.outputs['feature_vector']},\n",
    "        outputs=[\n",
    "        \"feature_scores\",\n",
    "        \"selected_features_count\",\n",
    "        \"top_features_vector\",\n",
    "        \"selected_features\",\n",
    "        ], \n",
    "    )\n",
    "    # train with hyper-paremeters\n",
    "    train = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"train\",\n",
    "        handler=\"train\",\n",
    "        params={\n",
    "            \"sample\": -1,\n",
    "            \"label_column\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"test_size\": 0.10,\n",
    "        },\n",
    "        hyperparams={\n",
    "            \"model_name\": [\n",
    "            \"transaction_fraud_rf\",\n",
    "            \"transaction_fraud_xgboost\",\n",
    "            \"transaction_fraud_adaboost\",\n",
    "        ],\n",
    "        \"model_class\": [\n",
    "            \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"sklearn.linear_model.LogisticRegression\",\n",
    "            \"sklearn.ensemble.AdaBoostClassifier\",\n",
    "        ], \n",
    "        },\n",
    "        hyper_param_options=HyperParamOptions(strategy=\"list\",\n",
    "                                          selector=\"max.accuracy\"),\n",
    "        inputs={\"dataset\": feature_selection.outputs[\"top_features_vector\"]},\n",
    "        outputs=[\"model\", \"test_set\"],\n",
    "    )\n",
    "    # test and visualize your model\n",
    "    test = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"evaluate\",\n",
    "        handler=\"evaluate\",\n",
    "        params={\n",
    "            \"label_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"model\": train.outputs[\"model\"],\n",
    "            \"drop_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "        },\n",
    "        inputs={\"dataset\": train.outputs[\"test_set\"]},\n",
    "    )\n",
    "    # Create a serverless function from the hub, add a feature enrichment router\n",
    "    # This will enrich and impute the request with data from the feature vector\n",
    "    serving_function = mlrun.import_function(\"hub://v2_model_server\",\n",
    "                                             new_name=\"serving\")\n",
    "    serving_function.set_topology(\n",
    "        \"router\",\n",
    "        mlrun.serving.routers.EnrichmentModelRouter( feature_vector_uri=\"short\", impute_policy={\"*\": \"$mean\"}), exist_ok=True\n",
    "    )\n",
    "    # Enable model monitoring\n",
    "    serving_function.set_tracking()\n",
    "    serving_function.save()\n",
    "    # deploy the model server, pass a list of trained models to serve\n",
    "    deploy = mlrun.deploy_function(\n",
    "        serving_function,\n",
    "        models=[{\"key\": \"fraud\", \"model_path\": train.outputs[\"model\"]}],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow/pipeline can be executed using the MLRun SDK (project.run() method) or using CLI commands (mlrun project), and can run directly from the source repo (GIT). See details in MLRun Projects and Automation documentation.\n",
    "\n",
    "You can set arguments and destinations for the different artifacts when you run the workflow. The pipeline progress and results are shown in the notebook. Alternatively, you can check the progress, logs, artifacts, and more, in the MLRun UI or the CI/CD system. The next part demonstrates how to run the pipeline with custom arguments using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'src/new_train_workflow.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running a pipeline\n",
    "\n",
    "First run the following code to save your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f56430bd9a0>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `run` MLRun project method to execute your workflow pipeline with Kubeflow Pipelines.\n",
    "\n",
    "You can pass **`arguments`** or set the **`artifact_path`** to specify a unique path for storing the workflow artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>Pipeline running (id=e259fae8-4b96-46cf-82b1-567d77b0bdba), <a href=\"https://dashboard.default-tenant.app.llm2.iguazio-cd0.com/mlprojects/fraud-demo-pengw/jobs/monitor-workflows/workflow/e259fae8-4b96-46cf-82b1-567d77b0bdba\" target=\"_blank\"><b>click here</b></a> to view the details in MLRun UI</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: kfp Pages: 1 -->\n",
       "<svg width=\"248pt\" height=\"260pt\"\n",
       " viewBox=\"0.00 0.00 248.05 260.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n",
       "<title>kfp</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-256 244.05,-256 244.05,4 -4,4\"/>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;1208513303 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;1208513303</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"125\" cy=\"-162\" rx=\"89.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"125\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">feature&#45;selection</text>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"125\" cy=\"-90\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"125\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">train</text>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;1208513303&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;1208513303&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125,-143.7C125,-135.98 125,-126.71 125,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.5,-118.1 125,-108.1 121.5,-118.1 128.5,-118.1\"/>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2961079792 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2961079792</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"122,-36 4,-36 0,-32 0,0 118,0 122,-4 122,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"118,-32 0,-32 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"118,-32 118,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"118,-32 122,-36 \"/>\n",
       "<text text-anchor=\"middle\" x=\"61\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">deploy&#45;serving</text>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2961079792 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2961079792</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M110.8,-73.46C102.89,-64.82 92.86,-53.85 83.88,-44.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"86.3,-41.48 76.96,-36.46 81.13,-46.2 86.3,-41.48\"/>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;549117497 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;549117497</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"190\" cy=\"-18\" rx=\"50.09\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">evaluate</text>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;549117497 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2816631112&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;549117497</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M139.43,-73.46C147.77,-64.48 158.45,-52.98 167.84,-42.87\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"170.47,-45.18 174.71,-35.47 165.34,-40.41 170.47,-45.18\"/>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2355563374 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2355563374</title>\n",
       "<g id=\"a_node3\"><a xlink:title=\"entity_timestamp_column param can not be specified without entity_rows param\">\n",
       "<ellipse fill=\"red\" stroke=\"black\" cx=\"125\" cy=\"-234\" rx=\"57.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"125\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">get&#45;vector</text>\n",
       "</a>\n",
       "</g>\n",
       "</g>\n",
       "<!-- fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2355563374&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;1208513303 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;2355563374&#45;&gt;fraud&#45;detection&#45;pipeline&#45;xnpcx&#45;1208513303</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M125,-215.7C125,-207.98 125,-198.71 125,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.5,-190.1 125,-180.1 121.5,-190.1 128.5,-190.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f5626aa7760>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Run Results</h2><h3>[info] Workflow e259fae8-4b96-46cf-82b1-567d77b0bdba finished with 1 errors</h3><br>click the hyper links below to see detailed results<br><table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>uid</th>\n",
       "      <th>start</th>\n",
       "      <th>state</th>\n",
       "      <th>name</th>\n",
       "      <th>parameters</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div title=\"ac92567f2cb74434aa1a9ae375738031\"><a href=\"https://dashboard.default-tenant.app.llm2.iguazio-cd0.com/mlprojects/fraud-demo-pengw/jobs/monitor/ac92567f2cb74434aa1a9ae375738031/overview\" target=\"_blank\" >...75738031</a></div></td>\n",
       "      <td>Aug 04 21:46:23</td>\n",
       "      <td><div style=\"color: red;\" title=\"entity_timestamp_column param can not be specified without entity_rows param\">error</div></td>\n",
       "      <td>get-vector</td>\n",
       "      <td><div class=\"dictlist\">feature_vector=transactions-fraud</div><div class=\"dictlist\">features=[]</div><div class=\"dictlist\">label_feature=labels.label</div><div class=\"dictlist\">entity_timestamp_column=timestamp</div><div class=\"dictlist\">target={'name': 'parquet', 'kind': 'parquet'}</div><div class=\"dictlist\">update_stats=True</div></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Pipeline run status Failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[287], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvector_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransactions-fraud\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels.label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/project.py:2278\u001b[0m, in \u001b[0;36mMlrunProject.run\u001b[0;34m(self, name, workflow_path, arguments, artifact_path, workflow_handler, namespace, sync, watch, dirty, ttl, engine, local, schedule, timeout, overwrite, source, cleanup_ttl)\u001b[0m\n\u001b[1;32m   2276\u001b[0m workflow_spec\u001b[38;5;241m.\u001b[39mclear_tmp()\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (timeout \u001b[38;5;129;01mor\u001b[39;00m watch) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m workflow_spec\u001b[38;5;241m.\u001b[39mschedule:\n\u001b[0;32m-> 2278\u001b[0m     \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_run_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/pipelines.py:668\u001b[0m, in \u001b[0;36m_KFPRunner.get_run_status\u001b[0;34m(project, run, timeout, expected_statuses, notifiers)\u001b[0m\n\u001b[1;32m    665\u001b[0m notifiers\u001b[38;5;241m.\u001b[39mpush(text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m, runs)\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_error:\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m raise_error\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, had_errors, text\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/pipelines.py:643\u001b[0m, in \u001b[0;36m_KFPRunner.get_run_status\u001b[0;34m(project, run, timeout, expected_statuses, notifiers)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout:\n\u001b[1;32m    642\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaiting for pipeline run completion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 643\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_statuses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_statuses\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;66;03m# push runs table also when we have errors\u001b[39;00m\n\u001b[1;32m    648\u001b[0m     raise_error \u001b[38;5;241m=\u001b[39m exc\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/pipelines.py:461\u001b[0m, in \u001b[0;36m_PipelineRunStatus.wait_for_completion\u001b[0;34m(self, timeout, expected_statuses)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_completion\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, expected_statuses\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_statuses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_statuses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/pipelines.py:609\u001b[0m, in \u001b[0;36m_KFPRunner.wait_for_completion\u001b[0;34m(run_id, project, timeout, expected_statuses)\u001b[0m\n\u001b[1;32m    607\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[1;32m    608\u001b[0m project_name \u001b[38;5;241m=\u001b[39m project\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mif\u001b[39;00m project \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 609\u001b[0m run_info \u001b[38;5;241m=\u001b[39m \u001b[43mwait_for_pipeline_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_statuses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_statuses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    615\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_info:\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/run.py:1193\u001b[0m, in \u001b[0;36mwait_for_pipeline_completion\u001b[0;34m(run_id, timeout, expected_statuses, namespace, remote, project)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_statuses:\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m expected_statuses:\n\u001b[0;32m-> 1193\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline run status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mmessage\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mmessage\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m         )\n\u001b[1;32m   1197\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished waiting for pipeline completion.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m run_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m namespace: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnamespace\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1203\u001b[0m )\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Pipeline run status Failed"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={'vector_name':\"transactions-fraud\",\n",
    "                'label_column':\"labels.label\",\n",
    "              }, \n",
    "    dirty=True, watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UI - WorkFlow](images/pipline-ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the model endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your model is deployed using the pipeline, you can invoke it as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your serving function\n",
    "serving_fn = project.get_function('serving')\n",
    "\n",
    "# Choose an id for your test\n",
    "sample_id = 'C1000148617'\n",
    "model_inference_path = '/v2/models/fraud/infer'\n",
    "\n",
    "# Send our sample ID for predcition\n",
    "serving_fn.invoke(path=model_inference_path,\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You've completed Part 2 of the model training with the feature store.\n",
    "Proceed to part 5 to learn how to deploy and monitor the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proof-reading",
   "language": "python",
   "name": "conda-env-.conda-proof-reading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
