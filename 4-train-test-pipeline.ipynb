{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Validation Pipeline\n",
    "Now that you have created features, you can use them to train one or more models. In this section, you will generate feature vectors with multiple features from one or more feature sets and feed them into an automated ML training and testing pipeline to create high-quality models.\n",
    "\n",
    "The ML pipeline can be triggered and tracked manually during the interactive devel‐ opment, or it can be saved (into Git) and be executed automatically on a given schedule or as a reaction to different events (such as code modification, CI/CD, data changes, model drift, and so on). See MLRun project and CI/CD documentation for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'fraud-demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 21:00:05,072 [info] Project loaded successfully: {'project_name': 'fraud-demo'}\n"
     ]
    }
   ],
   "source": [
    "import mlrun\n",
    "\n",
    "# Initialize the MLRun project object\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Names with underscore '_' are about to be deprecated, use dashes '-' instead. Replacing underscores with dashes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.serving.ServingRuntime at 0x7f564006a9d0>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.set_function(\"hub://get_offline_features\",\"get_vector\",)\n",
    "project.set_function(\"hub://feature_selection\",\"feature-selection\",)\n",
    "project.set_function(\"hub://auto_trainer\",\"train\")\n",
    "project.set_function(\"hub://auto_trainer\",\"evaluate\")\n",
    "project.set_function(\"hub://v2_model_server\", \"serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f56279b5490>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set project level parameters and save\n",
    "project.spec.params = {'label_column': 'label'}\n",
    "project.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kind: project\n",
      "metadata:\n",
      "  name: fraud-demo-pengw\n",
      "  created: '2023-08-04T18:02:33.655000'\n",
      "spec:\n",
      "  params:\n",
      "    label_column: label\n",
      "  functions:\n",
      "  - url: hub://feature_selection\n",
      "    name: feature-selection\n",
      "  - url: hub://auto_trainer\n",
      "    name: train\n",
      "  - url: hub://v2_model_server\n",
      "    name: serving\n",
      "  - url: hub://get_offline_features\n",
      "    name: get-vector\n",
      "  - url: hub://auto_trainer\n",
      "    name: evaluate\n",
      "  workflows:\n",
      "  - path: src/new_train_workflow.py\n",
      "    name: main\n",
      "  artifacts: []\n",
      "  conda: ''\n",
      "  source: git@github.com:pengwei715/demo-fraud.git#refs/heads/feature/align_with_book\n",
      "  origin_url: git@github.com:pengwei715/demo-fraud.git#refs/heads/feature/align_with_book\n",
      "  desired_state: online\n",
      "  owner: pengw\n",
      "  build:\n",
      "    commands: []\n",
      "    requirements: []\n",
      "  custom_packagers: []\n",
      "status:\n",
      "  state: online\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(project.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading projects from GIT\n",
    "\n",
    "After you saved your project and its elements (functions, workflows, artifacts, etc.) you can commit all your changes to a \n",
    "GIT repository. This can be done using standard GIT tools or using MLRun `project` methods such as `pull`, `push`, \n",
    "`remote`, which calls the Git API for you.\n",
    "\n",
    "Projects can then be loaded from Git using MLRun `load_project` method, for example: \n",
    "\n",
    "    project = mlrun.load_project(\"./myproj\", \"git://github.com/mlrun/project-demo.git\", name=project_name)\n",
    "    \n",
    "or using MLRun CLI:\n",
    "\n",
    "    mlrun project -n myproj -u \"git://github.com/mlrun/project-demo.git\" ./myproj\n",
    "    \n",
    "Read [CI/CD integration](../../projects/ci-integration.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Evaluating a Feature Vector\n",
    "\n",
    "Models are trained with multiple features, which can arrive from different feature sets and be collected into training (feature) vectors. Feature stores know how to correctly combine the features into a vector by implementing smart JOINs and assessing the time dimension (time traveling).\n",
    "To define a feature vector, you need to specify a name, the list of features it contains, the target features (labels), and other optional parameters. Features are specified as `<FeatureSet>.<Feature> or <FeatureSet>.*`  (all the features in a feature set). The following part demonstrates how to create and use a feature vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MLRun's Feature Store\n",
    "import mlrun.feature_store as fstore\n",
    "\n",
    "# Define the list of features to use\n",
    "features = ['events.*',\n",
    "            'transactions.amount_max_2h', \n",
    "            'transactions.amount_sum_2h', \n",
    "            'transactions.amount_count_2h',\n",
    "            'transactions.amount_avg_2h', \n",
    "            'transactions.amount_max_12h', \n",
    "            'transactions.amount_sum_12h',\n",
    "            'transactions.amount_count_12h', \n",
    "            'transactions.amount_avg_12h', \n",
    "            'transactions.amount_max_24h',\n",
    "            'transactions.amount_sum_24h', \n",
    "            'transactions.amount_count_24h', \n",
    "            'transactions.amount_avg_24h',\n",
    "            'transactions.es_transportation_sum_14d', \n",
    "            'transactions.es_health_sum_14d',\n",
    "            'transactions.es_otherservices_sum_14d', \n",
    "            'transactions.es_food_sum_14d',\n",
    "            'transactions.es_hotelservices_sum_14d', \n",
    "            'transactions.es_barsandrestaurants_sum_14d',\n",
    "            'transactions.es_tech_sum_14d', \n",
    "            'transactions.es_sportsandtoys_sum_14d',\n",
    "            'transactions.es_wellnessandbeauty_sum_14d', \n",
    "            'transactions.es_hyper_sum_14d',\n",
    "            'transactions.es_fashion_sum_14d', \n",
    "            'transactions.es_home_sum_14d', \n",
    "            'transactions.es_travel_sum_14d', \n",
    "            'transactions.es_leisure_sum_14d',\n",
    "            'transactions.gender_F',\n",
    "            'transactions.gender_M',\n",
    "            'transactions.step', \n",
    "            'transactions.amount', \n",
    "            'transactions.timestamp_hour',\n",
    "            'transactions.timestamp_day_of_week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature vector name for future reference\n",
    "fv_name = 'transactions-fraud'\n",
    "\n",
    "# Define the feature vector using the feature store (fstore)\n",
    "transactions_fv = fstore.FeatureVector(fv_name, \n",
    "                          features, \n",
    "                          label_feature=\"labels.label\",\n",
    "                          description='Predicting a fraudulent transaction')\n",
    "\n",
    "# Save the feature vector in the feature store\n",
    "transactions_fv.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'store://feature-vectors/fraud-demo-pengw/transactions-fraud'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_fv.uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the feature vector data\n",
    "\n",
    "Obtain the values of the features in the feature vector, to ensure the data appears as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 21:00:37,935 [info] wrote target: {'name': 'parquet', 'kind': 'parquet', 'path': 'v3io:///projects/fraud-demo-pengw/FeatureStore/transactions-fraud/parquet/vectors/transactions-fraud-latest.parquet', 'status': 'ready', 'updated': '2023-08-04T21:00:37.935071+00:00', 'size': 151216, 'partitioned': True}\n"
     ]
    }
   ],
   "source": [
    "# Import the Parquet Target so you can directly save your dataset as a file\n",
    "from mlrun.datastore.targets import ParquetTarget\n",
    "\n",
    "# Get offline feature vector as dataframe and save the dataset to parquet\n",
    "train_dataset = fstore.get_offline_features(fv_name, target=ParquetTarget())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_password_change</th>\n",
       "      <th>event_details_change</th>\n",
       "      <th>event_login</th>\n",
       "      <th>amount_max_2h</th>\n",
       "      <th>amount_sum_2h</th>\n",
       "      <th>amount_count_2h</th>\n",
       "      <th>amount_avg_2h</th>\n",
       "      <th>amount_max_12h</th>\n",
       "      <th>amount_sum_12h</th>\n",
       "      <th>amount_count_12h</th>\n",
       "      <th>...</th>\n",
       "      <th>es_home_sum_14d</th>\n",
       "      <th>es_travel_sum_14d</th>\n",
       "      <th>es_leisure_sum_14d</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>timestamp_hour</th>\n",
       "      <th>timestamp_day_of_week</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.830000</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.406667</td>\n",
       "      <td>18.72</td>\n",
       "      <td>40.22</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>18.72</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.92</td>\n",
       "      <td>64.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.620000</td>\n",
       "      <td>25.92</td>\n",
       "      <td>64.86</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.92</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.085000</td>\n",
       "      <td>24.75</td>\n",
       "      <td>30.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.18</td>\n",
       "      <td>65.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.585000</td>\n",
       "      <td>64.18</td>\n",
       "      <td>65.17</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>64.18</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_password_change  event_details_change  event_login  amount_max_2h  \\\n",
       "0                      0                     0            1           1.83   \n",
       "1                      0                     0            1          18.72   \n",
       "2                      1                     0            0          25.92   \n",
       "3                      1                     0            0          24.75   \n",
       "4                      1                     0            0          64.18   \n",
       "\n",
       "   amount_sum_2h  amount_count_2h  amount_avg_2h  amount_max_12h  \\\n",
       "0           1.83              1.0       1.830000            1.83   \n",
       "1          40.22              3.0      13.406667           18.72   \n",
       "2          64.86              3.0      21.620000           25.92   \n",
       "3          30.17              2.0      15.085000           24.75   \n",
       "4          65.17              2.0      32.585000           64.18   \n",
       "\n",
       "   amount_sum_12h  amount_count_12h  ...  es_home_sum_14d  es_travel_sum_14d  \\\n",
       "0            1.83               1.0  ...              0.0                0.0   \n",
       "1           40.22               3.0  ...              0.0                0.0   \n",
       "2           64.86               3.0  ...              0.0                0.0   \n",
       "3           30.17               2.0  ...              0.0                0.0   \n",
       "4           65.17               2.0  ...              0.0                0.0   \n",
       "\n",
       "   es_leisure_sum_14d  gender_F  gender_M   step  amount  timestamp_hour  \\\n",
       "0                 0.0       0.0       1.0   72.0    1.83            19.0   \n",
       "1                 0.0       0.0       1.0   66.0   18.72            19.0   \n",
       "2                 0.0       0.0       1.0   27.0   25.92            19.0   \n",
       "3                 0.0       0.0       1.0  141.0   24.75            19.0   \n",
       "4                 0.0       1.0       0.0  124.0   64.18            19.0   \n",
       "\n",
       "   timestamp_day_of_week  label  \n",
       "0                    2.0    0.0  \n",
       "1                    2.0    0.0  \n",
       "2                    2.0    0.0  \n",
       "3                    2.0    0.0  \n",
       "4                    2.0    0.0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview your dataset\n",
    "train_dataset.to_dataframe().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and Running an Automated Training and Validation Pipeline\n",
    "\n",
    "MLRun allows the building of distributed ML pipelines that can handle data process‐ ing, automated feature selection, training, optimization, testing, deployments, and so on. Pipelines are composed of steps that run or deploy custom or library (from the MLRun hub) serverless functions. Pipelines can be run locally (for debugging or small-scale tasks), on a scalable Kubernetes cluster (using Kubeflow), or in a CI/CD system.\n",
    "\n",
    "The example consists of the following pipeline steps (all using pre-defined MLRun hub functions):\n",
    "\n",
    "1. Materialize a feature vector (using `hub://get_offline_features`). \n",
    "2. Select the most optimal features (using `hub://feature_selection`).\n",
    "3. Train the model with multiple algorithms (using `hub://auto_trainer`).\n",
    "4. Evaluate the model (using `hub://auto_trainer`).\n",
    "5. Deploy the model and its application to the test cluster (using `hub://v2_model_server`). The next section will explain the model and application pipeline in detail.\n",
    "\n",
    "Each step can accept the previous steps’ results or data, and generate results, multiple visual artifacts/charts, versioned data objects, and registered models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlrun\n",
    "from kfp import dsl\n",
    "\n",
    "from mlrun.model import HyperParamOptions\n",
    "\n",
    "\n",
    "# Create a Kubeflow Pipelines pipeline\n",
    "@dsl.pipeline(name=\"Fraud Detection Pipeline\",description=\"Detecting fraud from a transactions dataset\",)\n",
    "def pipeline( vector_name=\"transactions-fraud\", features=[], label_column=\"is_error\"):\n",
    "    project = mlrun.get_current_project() # Get FeatureVector\n",
    "    get_vector = mlrun.run_function(\n",
    "        \"hub://get_offline_features\",\n",
    "        name=\"get_vector\",\n",
    "        params={'feature_vector': vector_name,\n",
    "        'features': features,\n",
    "        'label_feature': label_column, \n",
    "        \"entity_timestamp_column\": \"timestamp\", \n",
    "        'target': {'name': 'parquet', 'kind': 'parquet'}, \n",
    "        \"update_stats\": True},\n",
    "        outputs=[\"feature_vector\"],\n",
    "    )\n",
    "    # Feature selection\n",
    "    feature_selection = mlrun.run_function(\n",
    "        \"hub://feature_selection\",\n",
    "        name=\"feature-selection\",\n",
    "        params={\n",
    "        \"output_vector_name\": \"short\",\n",
    "        \"label_column\": project.get_param(\"label_column\", \"label\"), \"k\": 18,\n",
    "        \"min_votes\": 2,\n",
    "        \"ignore_type_errors\": True,\n",
    "        }, \n",
    "        inputs={\"df_artifact\": get_vector.outputs['feature_vector']},\n",
    "        outputs=[\n",
    "        \"feature_scores\",\n",
    "        \"selected_features_count\",\n",
    "        \"top_features_vector\",\n",
    "        \"selected_features\",\n",
    "        ], \n",
    "    )\n",
    "    # train with hyper-paremeters\n",
    "    train = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"train\",\n",
    "        handler=\"train\",\n",
    "        params={\n",
    "            \"sample\": -1,\n",
    "            \"label_column\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"test_size\": 0.10,\n",
    "        },\n",
    "        hyperparams={\n",
    "            \"model_name\": [\n",
    "            \"transaction_fraud_rf\",\n",
    "            \"transaction_fraud_xgboost\",\n",
    "            \"transaction_fraud_adaboost\",\n",
    "        ],\n",
    "        \"model_class\": [\n",
    "            \"sklearn.ensemble.RandomForestClassifier\",\n",
    "            \"sklearn.linear_model.LogisticRegression\",\n",
    "            \"sklearn.ensemble.AdaBoostClassifier\",\n",
    "        ], \n",
    "        },\n",
    "        hyper_param_options=HyperParamOptions(strategy=\"list\",\n",
    "                                          selector=\"max.accuracy\"),\n",
    "        inputs={\"dataset\": feature_selection.outputs[\"top_features_vector\"]},\n",
    "        outputs=[\"model\", \"test_set\"],\n",
    "    )\n",
    "    # test and visualize your model\n",
    "    test = mlrun.run_function(\n",
    "        \"hub://auto_trainer\",\n",
    "        name=\"evaluate\",\n",
    "        handler=\"evaluate\",\n",
    "        params={\n",
    "            \"label_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "            \"model\": train.outputs[\"model\"],\n",
    "            \"drop_columns\": project.get_param(\"label_column\", \"label\"),\n",
    "        },\n",
    "        inputs={\"dataset\": train.outputs[\"test_set\"]},\n",
    "    )\n",
    "    # Create a serverless function from the hub, add a feature enrichment router\n",
    "    # This will enrich and impute the request with data from the feature vector\n",
    "    serving_function = mlrun.import_function(\"hub://v2_model_server\",\n",
    "                                             new_name=\"serving\")\n",
    "    serving_function.set_topology(\n",
    "        \"router\",\n",
    "        mlrun.serving.routers.EnrichmentModelRouter( feature_vector_uri=\"short\", impute_policy={\"*\": \"$mean\"}), exist_ok=True\n",
    "    )\n",
    "    # Enable model monitoring\n",
    "    serving_function.set_tracking()\n",
    "    serving_function.save()\n",
    "    # deploy the model server, pass a list of trained models to serve\n",
    "    deploy = mlrun.deploy_function(\n",
    "        serving_function,\n",
    "        models=[{\"key\": \"fraud\", \"model_path\": train.outputs[\"model\"]}],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow/pipeline can be executed using the MLRun SDK (project.run() method) or using CLI commands (mlrun project), and can run directly from the source repo (GIT). See details in MLRun Projects and Automation documentation.\n",
    "\n",
    "You can set arguments and destinations for the different artifacts when you run the workflow. The pipeline progress and results are shown in the notebook. Alternatively, you can check the progress, logs, artifacts, and more, in the MLRun UI or the CI/CD system. The next part demonstrates how to run the pipeline with custom arguments using the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the workflow file as \"main\"\n",
    "project.set_workflow('main', 'src/new_train_workflow.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running a pipeline\n",
    "\n",
    "First run the following code to save your project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mlrun.projects.project.MlrunProject at 0x7f56279b5490>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `run` MLRun project method to execute your workflow pipeline with Kubeflow Pipelines.\n",
    "\n",
    "You can pass **`arguments`** or set the **`artifact_path`** to specify a unique path for storing the workflow artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 21:09:30,313 [warning] WARNING!, you seem to have uncommitted git changes, use .push()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing type name was inferred as \"JsonArray\" based on the value \"[]\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2023-08-04 21:09:31,986 [error] error cannot submit pipeline: 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main: details: MLRunBadRequestError('Failed creating pipeline: (500)\\nReason: Internal Server Error\\nHTTP response headers: HTTPHeaderDict({\\'Content-Type\\': \\'application/json\\', \\'Date\\': \\'Fri, 04 Aug 2023 21:09:31 GMT\\', \\'Content-Length\\': \\'673\\'})\\nHTTP response body: {\"error\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"code\":13,\"message\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"details\":[{\"@type\":\"type.googleapis.com/api.Error\",\"error_message\":\"Internal Server Error\",\"error_details\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\"}]}\\n'), caused by: 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "error: cannot cannot submit pipeline, 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main: details: MLRunBadRequestError('Failed creating pipeline: (500)\\nReason: Internal Server Error\\nHTTP response headers: HTTPHeaderDict({\\'Content-Type\\': \\'application/json\\', \\'Date\\': \\'Fri, 04 Aug 2023 21:09:31 GMT\\', \\'Content-Length\\': \\'673\\'})\\nHTTP response body: {\"error\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"code\":13,\"message\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"details\":[{\"@type\":\"type.googleapis.com/api.Error\",\"error_message\":\"Internal Server Error\",\"error_details\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\"}]}\\n'), caused by: 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/errors.py:94\u001b[0m, in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mHTTPError, aiohttp\u001b[38;5;241m.\u001b[39mClientResponseError) \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMLRunBadRequestError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/db/httpdb.py:1397\u001b[0m, in \u001b[0;36mHTTPRunDB.submit_pipeline\u001b[0;34m(self, project, pipeline, arguments, experiment, run, namespace, artifact_path, ops, ttl, cleanup_ttl)\u001b[0m\n\u001b[1;32m   1396\u001b[0m     params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnamespace\u001b[39m\u001b[38;5;124m\"\u001b[39m: namespace, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m\"\u001b[39m: experiment, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m: run}\n\u001b[0;32m-> 1397\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprojects/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mproject\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/pipelines\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/db/httpdb.py:237\u001b[0m, in \u001b[0;36mHTTPRunDB.api_call\u001b[0;34m(self, method, path, error, params, body, json, headers, timeout, version)\u001b[0m\n\u001b[1;32m    236\u001b[0m         error \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_details\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error \u001b[38;5;28;01melse\u001b[39;00m error_details\n\u001b[0;32m--> 237\u001b[0m         \u001b[43mmlrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m mlrun\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mraise_for_status(response, error)\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/errors.py:105\u001b[0m, in \u001b[0;36mraise_for_status\u001b[0;34m(response, message)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m STATUS_ERRORS[status_code](error_message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mMLRunBadRequestError\u001b[0m: 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main: details: MLRunBadRequestError('Failed creating pipeline: (500)\\nReason: Internal Server Error\\nHTTP response headers: HTTPHeaderDict({\\'Content-Type\\': \\'application/json\\', \\'Date\\': \\'Fri, 04 Aug 2023 21:09:31 GMT\\', \\'Content-Length\\': \\'673\\'})\\nHTTP response body: {\"error\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"code\":13,\"message\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"details\":[{\"@type\":\"type.googleapis.com/api.Error\",\"error_message\":\"Internal Server Error\",\"error_details\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\"}]}\\n')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_id \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvector_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransactions-fraud\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_column\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels.label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfraud_detection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/project.py:2258\u001b[0m, in \u001b[0;36mMlrunProject.run\u001b[0;34m(self, name, workflow_path, arguments, artifact_path, workflow_handler, namespace, sync, watch, dirty, ttl, engine, local, schedule, timeout, overwrite, source, cleanup_ttl)\u001b[0m\n\u001b[1;32m   2255\u001b[0m     inner_engine \u001b[38;5;241m=\u001b[39m get_workflow_engine(workflow_spec\u001b[38;5;241m.\u001b[39mengine, local)\u001b[38;5;241m.\u001b[39mengine\n\u001b[1;32m   2256\u001b[0m workflow_spec\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m inner_engine \u001b[38;5;129;01mor\u001b[39;00m workflow_engine\u001b[38;5;241m.\u001b[39mengine\n\u001b[0;32m-> 2258\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mworkflow_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2259\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkflow_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkflow_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkflow_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msecrets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_secrets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2264\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2268\u001b[0m \u001b[38;5;66;03m# run is None when scheduling\u001b[39;00m\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run \u001b[38;5;129;01mand\u001b[39;00m run\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m mlrun\u001b[38;5;241m.\u001b[39mrun\u001b[38;5;241m.\u001b[39mRunStatuses\u001b[38;5;241m.\u001b[39mfailed:\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/projects/pipelines.py:586\u001b[0m, in \u001b[0;36m_KFPRunner.run\u001b[0;34m(cls, project, workflow_spec, name, workflow_handler, secrets, artifact_path, namespace, source)\u001b[0m\n\u001b[1;32m    583\u001b[0m     project\u001b[38;5;241m.\u001b[39mset_source(source\u001b[38;5;241m=\u001b[39msource)\n\u001b[1;32m    585\u001b[0m namespace \u001b[38;5;241m=\u001b[39m namespace \u001b[38;5;129;01mor\u001b[39;00m config\u001b[38;5;241m.\u001b[39mnamespace\n\u001b[0;32m--> 586\u001b[0m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43m_run_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkflow_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkflow_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mworkflow_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcleanup_ttl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkflow_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup_ttl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mworkflow_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mttl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m project\u001b[38;5;241m.\u001b[39mnotifiers\u001b[38;5;241m.\u001b[39mpush_pipeline_start_message(\n\u001b[1;32m    596\u001b[0m     project\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    597\u001b[0m     project\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommit_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28mid\u001b[39m,\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    600\u001b[0m )\n\u001b[1;32m    601\u001b[0m pipeline_context\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/run.py:1103\u001b[0m, in \u001b[0;36m_run_pipeline\u001b[0;34m(pipeline, arguments, project, experiment, run, namespace, artifact_path, ops, url, cleanup_ttl)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mldb\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun pipeline require access to remote api-service\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, please set the dbpath url\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1101\u001b[0m     )\n\u001b[0;32m-> 1103\u001b[0m pipeline_run_id \u001b[38;5;241m=\u001b[39m \u001b[43mmldb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcleanup_ttl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcleanup_ttl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline run id=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, check UI for progress\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline_run_id\n",
      "File \u001b[0;32m~/.conda/envs/proof-reading/lib/python3.9/site-packages/mlrun/db/httpdb.py:1407\u001b[0m, in \u001b[0;36mHTTPRunDB.submit_pipeline\u001b[0;34m(self, project, pipeline, arguments, experiment, run, namespace, artifact_path, ops, ttl, cleanup_ttl)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1406\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror cannot submit pipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_to_str(err)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror: cannot cannot submit pipeline, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_to_str(err)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m   1410\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbad resp!!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresp\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: error: cannot cannot submit pipeline, 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main: details: MLRunBadRequestError('Failed creating pipeline: (500)\\nReason: Internal Server Error\\nHTTP response headers: HTTPHeaderDict({\\'Content-Type\\': \\'application/json\\', \\'Date\\': \\'Fri, 04 Aug 2023 21:09:31 GMT\\', \\'Content-Length\\': \\'673\\'})\\nHTTP response body: {\"error\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"code\":13,\"message\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\",\"details\":[{\"@type\":\"type.googleapis.com/api.Error\",\"error_message\":\"Internal Server Error\",\"error_details\":\"Failed to create a new run.: InternalServerError: failed to generate the workflow.: Failed to verify parameters.: Invalid input error: Unrecognized input parameter: model_name\"}]}\\n'), caused by: 400 Client Error: Bad Request for url: http://mlrun-api:8080/api/v1/projects/fraud-demo-pengw/pipelines?namespace=default-tenant&experiment=fraud-demo-pengw-main"
     ]
    }
   ],
   "source": [
    "run_id = project.run(\n",
    "    'main',\n",
    "    arguments={'vector_name':\"transactions-fraud\",\n",
    "                'label_column':\"labels.label\",\n",
    "                'model_name':\"fraud_detection\"}, \n",
    "    dirty=True, watch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![UI - WorkFlow](images/pipline-ui.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the model endpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your model is deployed using the pipeline, you can invoke it as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your serving function\n",
    "serving_fn = project.get_function('serving')\n",
    "\n",
    "# Choose an id for your test\n",
    "sample_id = 'C1000148617'\n",
    "model_inference_path = '/v2/models/fraud/infer'\n",
    "\n",
    "# Send our sample ID for predcition\n",
    "serving_fn.invoke(path=model_inference_path,\n",
    "                  body={'inputs': [[sample_id]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "You've completed Part 2 of the model training with the feature store.\n",
    "Proceed to part 5 to learn how to deploy and monitor the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proof-reading",
   "language": "python",
   "name": "conda-env-.conda-proof-reading-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
